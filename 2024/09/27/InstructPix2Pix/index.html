<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>InstructPix2Pix: Learning to Follow Image Editing Instructions - Breynald Shelter</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Breynald Shelter"><meta name="msapplication-TileImage" content="https://raw.githubusercontent.com/Breynald/ImageSource/main/blogs/img/blog.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Breynald Shelter"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="We propose a method for editing images from human instructions: given an input image and a written instruction that tells the model what to do, our model follows these instructions to edit the image."><meta property="og:type" content="blog"><meta property="og:title" content="InstructPix2Pix: Learning to Follow Image Editing Instructions"><meta property="og:url" content="http://example.com/2024/09/27/InstructPix2Pix/"><meta property="og:site_name" content="Breynald Shelter"><meta property="og:description" content="We propose a method for editing images from human instructions: given an input image and a written instruction that tells the model what to do, our model follows these instructions to edit the image."><meta property="og:locale" content="en_US"><meta property="og:image" content="https://t.mwm.moe/fj?random=InstructPix2Pix"><meta property="article:published_time" content="2024-09-27T06:17:14.000Z"><meta property="article:modified_time" content="2024-09-28T05:37:28.080Z"><meta property="article:author" content="Breynald"><meta property="article:tag" content="Diffusion Model"><meta property="article:tag" content="Personalization"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://t.mwm.moe/fj?random=InstructPix2Pix"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com/2024/09/27/InstructPix2Pix/"},"headline":"InstructPix2Pix: Learning to Follow Image Editing Instructions","image":[],"datePublished":"2024-09-27T06:17:14.000Z","dateModified":"2024-09-28T05:37:28.080Z","author":{"@type":"Person","name":"Breynald"},"publisher":{"@type":"Organization","name":"Breynald Shelter","logo":{"@type":"ImageObject","url":"https://raw.githubusercontent.com/Breynald/ImageSource/main/blogs/img/logo.svg"}},"description":"We propose a method for editing images from human instructions: given an input image and a written instruction that tells the model what to do, our model follows these instructions to edit the image."}</script><link rel="canonical" href="http://example.com/2024/09/27/InstructPix2Pix/"><link rel="icon" href="https://raw.githubusercontent.com/Breynald/ImageSource/main/blogs/img/blog.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link data-pjax rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link data-pjax rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="https://raw.githubusercontent.com/Breynald/ImageSource/main/blogs/img/logo.svg" alt="Breynald Shelter" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a></div><div class="navbar-end"><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="https://t.mwm.moe/fj?random=InstructPix2Pix" alt="InstructPix2Pix: Learning to Follow Image Editing Instructions"></span></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-09-27T06:17:14.000Z" title="2024/9/27 14:17:14">2024-09-27</time></span><span class="level-item"><a class="link-muted" href="/categories/Paper/">Paper</a><span> / </span><a class="link-muted" href="/categories/Paper/Diffusion-Model/">Diffusion Model</a></span><span class="level-item">6 minutes read (About 848 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">InstructPix2Pix: Learning to Follow Image Editing Instructions</h1><div class="content"><p>We propose a method for editing images from human instructions: given an input image and a written instruction that tells the model what to do, our model follows these instructions to edit the image. To obtain training data for this problem, we combine the knowledge of two large pretrained models—a language model (GPT-3) and a text-to-image model (Stable Diffusion)—to generate a large dataset of image editing examples. Our conditional diffusion model, InstructPix2Pix, is trained on our generated data, and generalizes to real images and user-written instructions at inference time. Since it performs edits in the forward pass and does not require per-example fine-tuning or inversion, our model edits images quickly, in a matter of seconds. We show compelling editing results for a diverse collection of input images and written instructions.</p>
<span id="more"></span>

<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>we propose an approach for generating a paired dataset that combines multiple large models pretrained on different modalities: a large language model (GPT-3) and a text-to-image model (Stable Diffusion). These two models capture complementary knowledge about language and images that can be combined to create paired training data for a task spanning both modalities.</p>
<p>Our model directly performs the image edit in the forward pass, and does not require any additional example images, full descriptions of the input&#x2F;output images, or per-example finetuning.</p>
<p><img src="https://raw.githubusercontent.com/Breynald/ImageSource/main/blogs/InstructPix2Pix/Figure%201.png"></p>
<h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><p>We treat instruction-based image editing as a supervised learning problem:</p>
<ol>
<li>first, we generate a paired training dataset of text editing instructions and images before&#x2F;after the edit;</li>
<li>then, we train an image editing diffusion model on this generated dataset</li>
</ol>
<p><img src="https://raw.githubusercontent.com/Breynald/ImageSource/main/blogs/InstructPix2Pix/Figure%202.png"></p>
<h3 id="Generating-a-Multi-modal-Training-Dataset"><a href="#Generating-a-Multi-modal-Training-Dataset" class="headerlink" title="Generating a Multi-modal Training Dataset"></a>Generating a Multi-modal Training Dataset</h3><h4 id="Generating-Instructions-and-Paired-Captions"><a href="#Generating-Instructions-and-Paired-Captions" class="headerlink" title="Generating Instructions and Paired Captions"></a>Generating Instructions and Paired Captions</h4><p>We first operate entirely in the text domain, where we leverage a large language model to take in image captions and produce editing instructions and the resulting text captions after the edit, as shown in Figure 2a.  </p>
<p>See Table 1a for examples of our written instructions and output captions. Using this data, we fine-tuned the GPT-3 Davinci model for a single epoch using the default training parameters.</p>
<p><img src="https://raw.githubusercontent.com/Breynald/ImageSource/main/blogs/InstructPix2Pix/Figure%203.png"></p>
<p>See Table 1b for example GPT-3 generated data. Our dataset is created by generating a large number of edits and output captions using this trained model, where the input captions are real image captions from LAION-Aesthetics (excluding samples with duplicate captions or duplicate image URLs).</p>
<h4 id="Generating-Paired-Images-from-Paired-Captions"><a href="#Generating-Paired-Images-from-Paired-Captions" class="headerlink" title="Generating Paired Images from Paired Captions"></a>Generating Paired Images from Paired Captions</h4><p>One challenge in turning a pair of captions into a pair of corresponding images is that text-to-image models provide no guarantees about image consistency, even under very minor changes of the conditioning prompt.</p>
<p>We therefore use Prompt-to-Prompt, a recent method aimed at encouraging multiple generations from a text-to-image diffusion model to be similar.</p>
<img src="https://raw.githubusercontent.com/Breynald/ImageSource/main/blogs/InstructPix2Pix/Figure%204.png" style="zoom:80%;" />

<p>While this greatly helps assimilate generated images, different edits may require different amounts of change in image-space. We therefore generate 100 sample pairs of images per caption-pair, each with a random $p ∼ \mathcal{U}(0.1, 0.9)$, and filter these samples by using a CLIP-based metric. This metric measures the consistency of the change between the two images (in CLIP space) with the change between the two image captions.</p>
<h3 id="InstructPix2Pix"><a href="#InstructPix2Pix" class="headerlink" title="InstructPix2Pix"></a>InstructPix2Pix</h3><p>We use our generated training data to train a conditional diffusion model that edits images from written instructions. We base our model on Stable Diffusion, a large-scale text-to-image latent diffusion model.</p>
<p>Details about training referring to [1].</p>
<h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><p>We show instruction-based image editing results on a diverse set of real photographs and artwork, for many edit types and instruction wordings.</p>
<p><img src="https://raw.githubusercontent.com/Breynald/ImageSource/main/blogs/InstructPix2Pix/Figure%205.png"></p>
<p><img src="https://raw.githubusercontent.com/Breynald/ImageSource/main/blogs/InstructPix2Pix/Figure%206.png"></p>
<p><img src="https://raw.githubusercontent.com/Breynald/ImageSource/main/blogs/InstructPix2Pix/Figure%207.png"></p>
<h2 id="Limitations"><a href="#Limitations" class="headerlink" title="Limitations"></a>Limitations</h2><p>While our method is able to produce a wide variety of compelling edits to images, including style, medium, and other contextual changes, there still remain a number of limitations: </p>
<ol>
<li>Our model is limited by the visual quality of the generated dataset, and therefore by the diffusion model used to generate the imagery. </li>
<li>Furthermore, our method’s ability to generalize to new edits and make correct associations between visual changes and text instructions is limited by the human-written instructions used to fine-tune GPT-3, by the ability of GPT-3 to create instructions and modify captions, and by the ability of Prompt-to-Prompt to modify generated images.</li>
<li>Additionally, we find that performing many sequential edits sometimes causes accumulating artifacts.</li>
<li>Furthermore, there are well-documented biases in the data and the pretrained models that our method is based upon. The edited images from our method may inherit these biases or introduce others.</li>
</ol>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>[1]: Tim Brooks, Aleksander Holynski, Alexei A. Efros. InstructPix2Pix: Learning To Follow Image Editing Instructions. Proceedings of the IEEE&#x2F;CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023, pp. 18392-18402</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>InstructPix2Pix: Learning to Follow Image Editing Instructions</p><p><a href="http://example.com/2024/09/27/InstructPix2Pix/">http://example.com/2024/09/27/InstructPix2Pix/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Breynald</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2024-09-27</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2024-09-28</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Diffusion-Model/">Diffusion Model</a><a class="link-muted mr-2" rel="tag" href="/tags/Personalization/">Personalization</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2024/09/28/Inversion-based-Style-Transfer-with-Diffusion-Models/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Inversion-based Style Transfer with Diffusion Models</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2024/09/27/MathJax-fails-to-render-in-hexo-icarus/"><span class="level-item">MathJax fails to render in hexo icarus</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><script src="https://utteranc.es/client.js" repo="Breynald/Comments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async></script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://raw.githubusercontent.com/Breynald/ImageSource/main/blogs/img/avatar.jpg" alt="Breynald"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Breynald</p><p class="is-size-6 is-block">Zhejiang University</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Hangzhou China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">10</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">6</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">8</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Breynald" target="_blank" rel="me noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Github" href="https://github.com/Breynald"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Email" href="mailto:breynald@zju.edu.cn"><i class="fas fa-envelope"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#Introduction"><span class="level-left"><span class="level-item">1</span><span class="level-item">Introduction</span></span></a></li><li><a class="level is-mobile" href="#Method"><span class="level-left"><span class="level-item">2</span><span class="level-item">Method</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Generating-a-Multi-modal-Training-Dataset"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">Generating a Multi-modal Training Dataset</span></span></a></li><li><a class="level is-mobile" href="#InstructPix2Pix"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">InstructPix2Pix</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Results"><span class="level-left"><span class="level-item">3</span><span class="level-item">Results</span></span></a></li><li><a class="level is-mobile" href="#Limitations"><span class="level-left"><span class="level-item">4</span><span class="level-item">Limitations</span></span></a></li><li><a class="level is-mobile" href="#References"><span class="level-left"><span class="level-item">5</span><span class="level-item">References</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Bugs/"><span class="level-start"><span class="level-item">Bugs</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Code-Piece/"><span class="level-start"><span class="level-item">Code Piece</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Environment-Configuration/"><span class="level-start"><span class="level-item">Environment Configuration</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Paper/"><span class="level-start"><span class="level-item">Paper</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/Paper/Diffusion-Model/"><span class="level-start"><span class="level-item">Diffusion Model</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Paper/Humor/"><span class="level-start"><span class="level-item">Humor</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><figure class="media-left"><a class="image" href="/2024/10/12/The-Psychological-Process-of-Humor-Discourse-Comprehension-and-Audience-Response/"><img src="https://t.mwm.moe/fj?random=The Psychological Process of Humor Discourse Comprehension and Audience Response" alt="幽默语篇生成与理解的社会心理阐释"></a></figure><div class="media-content"><p class="date"><time dateTime="2024-10-12T08:21:04.000Z">2024-10-12</time></p><p class="title"><a href="/2024/10/12/The-Psychological-Process-of-Humor-Discourse-Comprehension-and-Audience-Response/">幽默语篇生成与理解的社会心理阐释</a></p><p class="categories"><a href="/categories/Paper/">Paper</a> / <a href="/categories/Paper/Humor/">Humor</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2024/10/01/Docker-container-configuration/"><img src="https://t.mwm.moe/fj?random=Docker container configuration" alt="Docker container configuration"></a></figure><div class="media-content"><p class="date"><time dateTime="2024-10-01T05:46:11.000Z">2024-10-01</time></p><p class="title"><a href="/2024/10/01/Docker-container-configuration/">Docker container configuration</a></p><p class="categories"><a href="/categories/Environment-Configuration/">Environment Configuration</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2024/09/28/Inversion-based-Style-Transfer-with-Diffusion-Models/"><img src="https://t.mwm.moe/fj?random=Inversion-based Style Transfer with Diffusion Models" alt="Inversion-based Style Transfer with Diffusion Models"></a></figure><div class="media-content"><p class="date"><time dateTime="2024-09-28T05:43:49.000Z">2024-09-28</time></p><p class="title"><a href="/2024/09/28/Inversion-based-Style-Transfer-with-Diffusion-Models/">Inversion-based Style Transfer with Diffusion Models</a></p><p class="categories"><a href="/categories/Paper/">Paper</a> / <a href="/categories/Paper/Diffusion-Model/">Diffusion Model</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2024/09/27/InstructPix2Pix/"><img src="https://t.mwm.moe/fj?random=InstructPix2Pix" alt="InstructPix2Pix: Learning to Follow Image Editing Instructions"></a></figure><div class="media-content"><p class="date"><time dateTime="2024-09-27T06:17:14.000Z">2024-09-27</time></p><p class="title"><a href="/2024/09/27/InstructPix2Pix/">InstructPix2Pix: Learning to Follow Image Editing Instructions</a></p><p class="categories"><a href="/categories/Paper/">Paper</a> / <a href="/categories/Paper/Diffusion-Model/">Diffusion Model</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2024/09/27/MathJax-fails-to-render-in-hexo-icarus/"><img src="https://t.mwm.moe/fj?random=MathJax fails to render in hexo icarus" alt="MathJax fails to render in hexo icarus"></a></figure><div class="media-content"><p class="date"><time dateTime="2024-09-27T01:08:11.000Z">2024-09-27</time></p><p class="title"><a href="/2024/09/27/MathJax-fails-to-render-in-hexo-icarus/">MathJax fails to render in hexo icarus</a></p><p class="categories"><a href="/categories/Bugs/">Bugs</a></p></div></article></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Bugs/"><span class="tag">Bugs</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Diffusion-Model/"><span class="tag">Diffusion Model</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docker/"><span class="tag">Docker</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Driving-Video-Deneration/"><span class="tag">Driving Video Deneration</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/HuggingFace/"><span class="tag">HuggingFace</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Humor/"><span class="tag">Humor</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Personalization/"><span class="tag">Personalization</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Survey/"><span class="tag">Survey</span><span class="tag">1</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="https://raw.githubusercontent.com/Breynald/ImageSource/main/blogs/img/logo.svg" alt="Breynald Shelter" height="28"></a><p class="is-size-7"><span>&copy; 2024 Breynald</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="GitHub" href="https://github.com/Breynald"><i class="fab fa-github"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Email" href="mailto:breynald@zju.edu.cn"><i class="fas fa-envelope"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script>if (false == true) {
			$(document).ready(function () {
				var int = setInterval(fixCount, 100);
				var uvOffSet = parseInt(0);
				var pvOffSet = parseInt(0);
				
				function fixCount() {
					var realUv = parseInt($("#busuanzi_value_site_uv").html())
					var realPv = parseInt($("#busuanzi_value_site_pv").html())
					if ($("#busuanzi_container_site_uv").css("display") != "none" && realUv > 0) {
						clearInterval(int);
						$("#busuanzi_value_site_uv").html(realUv + uvOffSet);
						$("#busuanzi_value_site_pv").html(realPv + pvOffSet);
					}
				}
			});
		}</script><script data-pjax src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script data-pjax src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/javascript" id="MathJax-script" async>MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      },
      chtml: {
        matchFontHeight: false
      }
    };</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script><script src="/js/pjax.js"></script><!--!--><!--!--><!--!--><script data-pjax src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>